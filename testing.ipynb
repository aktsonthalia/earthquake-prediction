{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from postprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binaries(labels, preds):\n",
    "    \n",
    "    assert(labels.size() == preds.size())\n",
    "    \n",
    "    size = labels.size()\n",
    "    total = math.prod([i for i in size])\n",
    "    \n",
    "    labels, preds = labels.view((total)), preds.view((total))\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0 \n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    events = 0\n",
    "    noEvents = 0\n",
    "    \n",
    "    for i in range(total):\n",
    "        \n",
    "        x, y = labels[i], preds[i]\n",
    "        \n",
    "        if x == 1:\n",
    "            \n",
    "            events += 1\n",
    "            \n",
    "            if y == 1:\n",
    "                tp += 1\n",
    "            \n",
    "            else:\n",
    "                fn += 1\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            noEvents += 1\n",
    "            \n",
    "            if y == 1:\n",
    "                fp += 1\n",
    "            \n",
    "            else:\n",
    "                tn += 1\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(\"{} evaluations in total.\".format(total))\n",
    "    print(\"{}/{} cells with earthquake activity were correctly identified. ({:.2f} %)\".format(tp, events, tp * 100.0 / events))\n",
    "    print(\"{}/{} cells with no earthquake activity were correctly identified. ({:.2f} %)\".format(tn, noEvents, tn * 100.0 / noEvents))\n",
    "    print(\"{}/{} positives turned out to be false.\".format(fp, fp+tp))\n",
    "    print(\"{}/{} negatives turned out to be false.\".format(fn, fn+tn)) \n",
    "    print(\"Preicision: {:.3f}\".format(precision))\n",
    "    print(\"Recall: {:.3f}\".format(recall))\n",
    "    print(\"F1 Score: {:.3f}\".format(f1))\n",
    "    print(\"Overall accuracy: {:.2f} %\".format((tp + tn) * 100.0 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, model, train_size, lookback_window, threshold=None, mode='binary'):\n",
    "    \n",
    "    a, b, c = data.size()\n",
    "    \n",
    "    train_size = int(train_size * a) - lookback_window\n",
    "    test_size = a - train_size - lookback_window\n",
    "    \n",
    "    labels_train = torch.zeros((train_size, 1, c))\n",
    "    preds_train = torch.zeros((train_size, 1, c))\n",
    "    \n",
    "    labels_test = torch.zeros((test_size, 1, c))\n",
    "    preds_test = torch.zeros((test_size, 1, c))\n",
    "    \n",
    "    for i in tqdm(range(a - lookback_window)):\n",
    "        \n",
    "        X = data[i : i+lookback_window]\n",
    "        y = data[i+lookback_window]\n",
    "        \n",
    "        out = model(X)\n",
    "        \n",
    "        if threshold:\n",
    "            out = threshold_based_binaries(out, threshold)\n",
    "        \n",
    "        if i < train_size:\n",
    "            labels_train[i] = y\n",
    "            preds_train[i] = out\n",
    "        \n",
    "        else:\n",
    "            labels_test[i-train_size] = y\n",
    "            preds_test[i-train_size] = out\n",
    "       \n",
    "    print(\"Evaluation results for training dataset:\")\n",
    "    \n",
    "    if mode == 'binary':\n",
    "        evaluate_binaries(labels_train, preds_train)\n",
    "    \n",
    "    print(\"Evaluation results for training dataset:\")\n",
    "    \n",
    "    if mode == 'binary':\n",
    "        evaluate_binaries(labels_test, preds_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
